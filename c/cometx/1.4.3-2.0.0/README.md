# Comparing `tmp/cometx-1.4.3-py3-none-any.whl.zip` & `tmp/cometx-2.0.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,30 +1,30 @@
-Zip file size: 60297 bytes, number of entries: 28
+Zip file size: 61804 bytes, number of entries: 28
 -rw-rw-r--  2.0 unx      546 b- defN 24-Jan-08 19:44 cometx/__init__.py
 -rw-rw-r--  2.0 unx     1227 b- defN 23-Nov-10 01:51 cometx/_typing.py
--rw-rw-r--  2.0 unx      642 b- defN 24-Apr-17 18:37 cometx/_version.py
+-rw-rw-r--  2.0 unx      642 b- defN 24-Apr-21 13:08 cometx/_version.py
 -rw-rw-r--  2.0 unx     5468 b- defN 24-Mar-01 14:40 cometx/api.py
 -rw-rw-r--  2.0 unx    32107 b- defN 23-Nov-28 14:15 cometx/generate_utils.py
 -rw-rw-r--  2.0 unx     5065 b- defN 24-Jan-30 12:08 cometx/utils.py
 -rw-rw-r--  2.0 unx     3068 b- defN 24-Mar-13 13:53 cometx/cli/__init__.py
 -rw-rw-r--  2.0 unx     4908 b- defN 24-Mar-13 13:53 cometx/cli/config.py
--rw-rw-r--  2.0 unx    23328 b- defN 24-Apr-17 18:38 cometx/cli/copy.py
+-rw-rw-r--  2.0 unx    26091 b- defN 24-Apr-21 13:07 cometx/cli/copy.py
 -rw-rw-r--  2.0 unx     3891 b- defN 23-Nov-29 19:06 cometx/cli/delete_assets.py
--rw-rw-r--  2.0 unx     8053 b- defN 24-Apr-17 11:45 cometx/cli/download.py
+-rw-rw-r--  2.0 unx     8496 b- defN 24-Apr-19 12:01 cometx/cli/download.py
 -rw-rw-r--  2.0 unx     2255 b- defN 24-Feb-19 13:03 cometx/cli/list_command.py
 -rw-rw-r--  2.0 unx     9772 b- defN 24-Jan-30 19:31 cometx/cli/log.py
--rw-rw-r--  2.0 unx     4289 b- defN 24-Jan-08 19:45 cometx/cli/reproduce.py
+-rw-rw-r--  2.0 unx     4423 b- defN 24-Apr-18 14:07 cometx/cli/reproduce.py
 -rw-rw-r--  2.0 unx     6777 b- defN 24-Feb-08 14:09 cometx/cli/utils.py
 -rw-rw-r--  2.0 unx      388 b- defN 24-Jan-08 19:43 cometx/framework/__init__.py
--rw-rw-r--  2.0 unx    17359 b- defN 24-Apr-17 18:14 cometx/framework/wandb.py
+-rw-rw-r--  2.0 unx    22809 b- defN 24-Apr-21 13:07 cometx/framework/wandb.py
 -rw-rw-r--  2.0 unx      443 b- defN 24-Jan-08 19:45 cometx/framework/comet/__init__.py
--rw-rw-r--  2.0 unx    45984 b- defN 24-Apr-17 11:45 cometx/framework/comet/download_manager.py
+-rw-rw-r--  2.0 unx    46062 b- defN 24-Apr-21 11:45 cometx/framework/comet/download_manager.py
 -rw-rw-r--  2.0 unx      379 b- defN 23-Nov-28 14:15 cometx/tools/__init__.py
 -rw-rw-r--  2.0 unx     2473 b- defN 23-Nov-28 14:15 cometx/tools/dataset.py
 -rw-rw-r--  2.0 unx    10560 b- defN 23-Nov-28 14:15 cometx/tools/pointcloud.py
--rw-r--r--  2.0 unx    11357 b- defN 24-Apr-17 18:38 cometx-1.4.3.dist-info/LICENSE
--rw-rw-r--  2.0 unx    11385 b- defN 24-Apr-17 18:38 cometx-1.4.3.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 24-Apr-17 18:38 cometx-1.4.3.dist-info/WHEEL
--rw-r--r--  2.0 unx       43 b- defN 24-Apr-17 18:38 cometx-1.4.3.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        7 b- defN 24-Apr-17 18:38 cometx-1.4.3.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2231 b- defN 24-Apr-17 18:38 cometx-1.4.3.dist-info/RECORD
-28 files, 214097 bytes uncompressed, 56759 bytes compressed:  73.5%
+-rw-r--r--  2.0 unx    11357 b- defN 24-Apr-21 13:08 cometx-2.0.0.dist-info/LICENSE
+-rw-rw-r--  2.0 unx    11385 b- defN 24-Apr-21 13:08 cometx-2.0.0.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 24-Apr-21 13:08 cometx-2.0.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       43 b- defN 24-Apr-21 13:08 cometx-2.0.0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        7 b- defN 24-Apr-21 13:08 cometx-2.0.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2231 b- defN 24-Apr-21 13:08 cometx-2.0.0.dist-info/RECORD
+28 files, 222965 bytes uncompressed, 58266 bytes compressed:  73.9%
```

## zipnote {}

```diff
@@ -60,26 +60,26 @@
 
 Filename: cometx/tools/dataset.py
 Comment: 
 
 Filename: cometx/tools/pointcloud.py
 Comment: 
 
-Filename: cometx-1.4.3.dist-info/LICENSE
+Filename: cometx-2.0.0.dist-info/LICENSE
 Comment: 
 
-Filename: cometx-1.4.3.dist-info/METADATA
+Filename: cometx-2.0.0.dist-info/METADATA
 Comment: 
 
-Filename: cometx-1.4.3.dist-info/WHEEL
+Filename: cometx-2.0.0.dist-info/WHEEL
 Comment: 
 
-Filename: cometx-1.4.3.dist-info/entry_points.txt
+Filename: cometx-2.0.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: cometx-1.4.3.dist-info/top_level.txt
+Filename: cometx-2.0.0.dist-info/top_level.txt
 Comment: 
 
-Filename: cometx-1.4.3.dist-info/RECORD
+Filename: cometx-2.0.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## cometx/_version.py

```diff
@@ -8,9 +8,9 @@
 #
 #  Sign up for free at http://www.comet-ml.com
 #  Copyright (C) 2015-2022 Comet ML INC
 #  This file can not be copied and/or distributed without
 #  the express permission of Comet ML Inc.
 # *******************************************************
 
-version_info = (1, 4, 3)
+version_info = (2, 0, 0)
 __version__ = ".".join(map(str, version_info))
```

## cometx/cli/copy.py

```diff
@@ -33,16 +33,14 @@
 | Source (below)     |                      |                        |
 |--------------------|----------------------|------------------------|
 | WORKSPACE          | Copies all projects  | N/A                    |
 | WORKSPACE/PROJ     | N/A                  | Copies all experiments |
 | WORKSPACE/PROJ/EXP | N/A                  | Copies experiment      |
 """
 
-# FIXME: how to have output without updating output to experiment?
-
 import argparse
 import glob
 import json
 import os
 import sys
 
 from comet_ml import API, APIExperiment, Artifact, Experiment, OfflineExperiment
@@ -247,14 +245,26 @@
             auto_histogram_tensorboard_logging=False,
             auto_histogram_epoch_rate=1,
             auto_histogram_weight_logging=False,
             auto_histogram_gradient_logging=False,
             auto_histogram_activation_logging=False,
             experiment_key=None,
         )
+
+        def filter_messages(method):
+            def filtered_method(message):
+                if hasattr(message, "context") and message.context == "ignore":
+                    return
+                method(message)
+
+            return filtered_method
+
+        experiment.streamer.put_message_in_q = filter_messages(
+            experiment.streamer.put_message_in_q
+        )
         return experiment
 
     def get_experiment_folders(self, workspace_src, project_src, experiment_src):
         for path in glob.iglob(f"{workspace_src}/{project_src}/{experiment_src}"):
             if any(
                 [path.endswith("~"), path.endswith(".json"), path.endswith(".jsonl")]
             ):
@@ -296,42 +306,42 @@
                     )
                     experiment.log_other("Name", "Reports")
                 experiment.log_artifact(artifact)
             if experiment:
                 experiment.end()
             self.copied_reports = True
 
-        # if project doesn't exist, create it
         experiment = self.create_experiment(workspace_dst, project_dst)
-
         # copy experiment_folder stuff to experiment
         # copy all resources to existing or new experiment
         self.log_all(experiment, experiment_folder)
         experiment.end()
         print(
             f"Uploading {experiment.offline_directory}/{experiment._get_offline_archive_file_name()}"
         )
         os.system(
             f"comet upload {experiment.offline_directory}/{experiment._get_offline_archive_file_name()}"
         )
 
     def log_metadata(self, experiment, filename):
         if self.debug:
-            print("log_metadata...")
+            with experiment.context_manager("ignore"):
+                print("log_metadata...")
         if os.path.exists(filename):
             metadata = json.load(open(filename))
             experiment.add_tags(metadata["tags"])
             if metadata["fileName"] == "Jupyter interactive":
                 experiment.set_filename(metadata["fileName"])
             elif metadata["fileName"] is not None:
                 experiment.set_filename(os.path.join(metadata["fileName"]))
 
     def log_system_details(self, experiment, filename):
         if self.debug:
-            print("log_system_details...")
+            with experiment.context_manager("ignore"):
+                print("log_system_details...")
         if os.path.exists(filename):
             system = json.load(open(filename))
 
             ## System info:
             message = SystemDetailsMessage.create(
                 context=experiment.context,
                 use_http_messages=experiment.streamer.use_http_messages,
@@ -350,92 +360,111 @@
                 python_version=system["pythonVersion"],
                 user=system["user"],
             )
             experiment._enqueue_message(message)
 
     def log_graph(self, experiment, filename):
         if self.debug:
-            print("log_graph...")
+            with experiment.context_manager("ignore"):
+                print("log_graph...")
         if os.path.exists(filename):
             experiment.set_model_graph(open(filename).read())
 
     def log_assets(self, experiment, path, assets_metadata):
         if self.debug:
-            print("log_assets...")
+            with experiment.context_manager("ignore"):
+                print("log_assets...")
         for log_filename in assets_metadata:
+            log_as_filename = assets_metadata[log_filename].get(
+                "logAsFileName",
+                None,
+            )
+            step = assets_metadata[log_filename].get("step", None)
+            epoch = assets_metadata[log_filename].get("epoch", None)
             asset_type = assets_metadata[log_filename].get("type", None)
             asset_type = asset_type if asset_type else "asset"
             if asset_type in self.ignore:
                 continue
             if log_filename.startswith("/"):
                 filename = os.path.join(path, asset_type, log_filename[1:])
             else:
                 filename = os.path.join(path, asset_type, log_filename)
 
             if not os.path.isfile(filename):
-                print("Missing file %r: unable to copy" % filename)
+                with experiment.context_manager("ignore"):
+                    print("Missing file %r: unable to copy" % filename)
                 continue
 
             metadata = assets_metadata[log_filename].get("metadata")
             metadata = json.loads(metadata) if metadata else {}
 
             if asset_type == "notebook":
                 experiment.log_notebook(filename)  # done!
+            elif asset_type == "video":
+                name = os.path.basename(filename)
+                binary_io = open(filename, "rb")
+
+                experiment.log_video(
+                    binary_io, name=log_as_filename or name, step=step, epoch=epoch
+                )  # done!
                 # FIXME:
-                # elif asset_type == "confusion-matrix":
-                # TODO: what to do about assets referenced in matrix?
+                # TODO: what to do about assets referenced in confusion matrix?
                 # elif asset_type == "embedding":
                 # TODO: what to do about assets referenced in embedding?
             elif asset_type == "model-element":
                 name = os.path.basename(filename)
                 experiment.log_model(name, filename)
             else:
                 binary_io = open(filename, "rb")
 
                 experiment._log_asset(
                     binary_io,
-                    file_name=log_filename,
+                    file_name=log_as_filename or log_filename,
                     copy_to_tmp=True,
                     asset_type=asset_type,
                     metadata=metadata,
-                    step=assets_metadata[log_filename].get("step", None),
+                    step=step,
                 )  # done!
 
     def log_code(self, experiment, filename):
         """ """
         if self.debug:
-            print("log_code...")
+            with experiment.context_manager("ignore"):
+                print("log_code...")
         if os.path.exists(filename):
             if os.path.isfile(filename):
                 experiment.log_code(str(filename))
             elif os.path.isdir(filename):
                 experiment.log_code(folder=str(filename))
 
     def log_requirements(self, experiment, filename):
         """
         Requirements (pip packages)
         """
         if self.debug:
-            print("log_requirements...")
+            with experiment.context_manager("ignore"):
+                print("log_requirements...")
         if os.path.exists(filename):
             installed_packages_list = [package.strip() for package in open(filename)]
             if installed_packages_list is None:
                 return
             message = InstalledPackagesMessage.create(
                 context=experiment.context,
                 use_http_messages=experiment.streamer.use_http_messages,
                 installed_packages=installed_packages_list,
             )
             experiment._enqueue_message(message)
 
     def log_metrics(self, experiment, filename):
         """ """
-        if self.debug:
-            print("log_metrics...")
         if os.path.exists(filename):
+            if self.debug:
+                with experiment.context_manager("ignore"):
+                    print("log_metrics %s..." % filename)
+
             for line in open(filename):
                 dict_line = json.loads(line)
                 name = dict_line["metricName"]
                 if name.startswith("sys.") and "system-metrics" in self.ignore:
                     continue
                 value = dict_line["metricValue"]
                 step = dict_line["step"]
@@ -445,53 +474,74 @@
                 message = MetricMessage(
                     context=context,
                     timestamp=timestamp,
                 )
                 message.set_metric(name, value, step=step, epoch=epoch)
                 experiment._enqueue_message(message)
 
+    def log_metrics_split(self, experiment, folder):
+        """ """
+        summary_filename = os.path.join(folder, "metrics_summary.jsonl")
+        if os.path.exists(summary_filename):
+            if self.debug:
+                with experiment.context_manager("ignore"):
+                    print("log_metrics from %s..." % summary_filename)
+
+            for line in open(summary_filename):
+                metric_summary = json.loads(line)
+                self.log_metrics(
+                    experiment,
+                    os.path.join(
+                        folder, "metrics", "metric_%05d.jsonl" % metric_summary["count"]
+                    ),
+                )
+
     def log_parameters(self, experiment, filename):
         """ """
         if self.debug:
-            print("log_parameters...")
+            with experiment.context_manager("ignore"):
+                print("log_parameters...")
         if os.path.exists(filename):
             parameters = json.load(open(filename))
-            for parameter in parameters:
-                name = parameter["name"]
-                value = parameter["valueCurrent"]
-                experiment.log_parameter(name, value)
+            parameter_dictionary = {
+                parameter["name"]: parameter["valueCurrent"] for parameter in parameters
+            }
+            experiment.log_parameters(parameter_dictionary, nested_support=True)
 
     def log_others(self, experiment, filename):
         """ """
         if self.debug:
-            print("log_others...")
+            with experiment.context_manager("ignore"):
+                print("log_others...")
         if os.path.exists(filename):
             for line in open(filename):
                 dict_line = json.loads(line)
                 name = dict_line["name"]
                 value = dict_line["valueCurrent"]
                 experiment.log_other(key=name, value=value)
 
     def log_output(self, experiment, output_file):
         """ """
         if self.debug:
-            print("log_output...")
+            with experiment.context_manager("ignore"):
+                print("log_output...")
         if os.path.exists(output_file):
             for line in open(output_file):
                 message = StandardOutputMessage.create(
                     context=experiment.context,
                     use_http_messages=experiment.streamer.use_http_messages,
                     output=line,
                     stderr=False,
                 )
                 experiment._enqueue_message(message)
 
     def log_html(self, experiment, filename):
         if self.debug:
-            print("log_html...")
+            with experiment.context_manager("ignore"):
+                print("log_html...")
         if os.path.exists(filename):
             html = open(filename).read()
             message = HtmlMessage.create(
                 context=experiment.context,
                 use_http_messages=experiment.streamer.use_http_messages,
                 html=html,
             )
@@ -538,17 +588,20 @@
             if upload_message:
                 experiment._enqueue_message(upload_message)
 
     def log_all(self, experiment, experiment_folder):
         """ """
         # FIXME: missing notes (edited by human, not logged programmatically)
         if "metrics" not in self.ignore:
+            # All together, in one file:
             self.log_metrics(
                 experiment, os.path.join(experiment_folder, "metrics.jsonl")
             )
+            # In separate files:
+            self.log_metrics_split(experiment, experiment_folder)
 
         if "metadata" not in self.ignore:
             self.log_metadata(
                 experiment, os.path.join(experiment_folder, "metadata.json")
             )
 
         if "parameters" not in self.ignore:
@@ -587,14 +640,19 @@
 
         if "model-graph" not in self.ignore:
             self.log_graph(
                 experiment, os.path.join(experiment_folder, "run/graph_definition.txt")
             )
 
         if "html" not in self.ignore:
+            # NOTE: also logged as html asset
+            html_filenames = os.path.join(experiment_folder, "assets", "html", "*")
+            for html_filename in glob.glob(html_filenames):
+                self.log_html(experiment, html_filename)
+            # Deprecated:
             self.log_html(
                 experiment,
                 os.path.join(experiment_folder, "experiment.html"),
             )
 
         if "system-details" not in self.ignore:
             self.log_system_details(
@@ -606,14 +664,17 @@
                 experiment, os.path.join(experiment_folder, "run", "git_metdata.json")
             )
             self.log_git_patch(
                 experiment, os.path.join(experiment_folder, "run", "git_diff.patch")
             )
 
         if "code" not in self.ignore:
+            code_folder = os.path.join(experiment_folder, "run", "code")
+            self.log_code(experiment, code_folder)
+            # Deprecated:
             self.log_code(
                 experiment, os.path.join(experiment_folder, "run", "script.py")
             )
 
 
 def main(args):
     parser = argparse.ArgumentParser(
```

## cometx/cli/download.py

```diff
@@ -190,20 +190,21 @@
 
     try:
         downloader = DownloadManager()
     except ValueError:
         display_invalid_api_key()
         return
 
+    max_workers = (
+        min(32, os.cpu_count() + 4)
+        if parsed_args.parallel is None
+        else parsed_args.parallel
+    )
+
     if parsed_args.FROM == "comet":
-        max_workers = (
-            min(32, os.cpu_count() + 4)
-            if parsed_args.parallel is None
-            else parsed_args.parallel
-        )
         try:
             downloader.download(
                 comet_path=parsed_args.PATH,
                 include=parsed_args.RESOURCE,
                 ignore=parsed_args.ignore,
                 output=parsed_args.output,
                 use_name=parsed_args.use_name,
@@ -214,14 +215,15 @@
                 asset_type=parsed_args.asset_type,
                 overwrite=parsed_args.overwrite,
                 skip=parsed_args.skip,
                 debug=parsed_args.debug,
                 query=parsed_args.query,
                 max_workers=max_workers,
             )
+            print("Waiting on threaded downloads...")
             downloader.end()
         except InvalidAPIKey:
             display_invalid_api_key()
         except Exception as exc:
             if parsed_args.debug:
                 raise exc from None
             else:
@@ -240,16 +242,28 @@
             force=parsed_args.force,
             filename=parsed_args.filename,
             asset_type=parsed_args.asset_type,
             overwrite=parsed_args.overwrite,
             skip=parsed_args.skip,
             debug=parsed_args.debug,
             query=parsed_args.query,
+            max_workers=max_workers,
         )
-        dm.download(parsed_args.PATH)
+
+        try:
+            dm.download(parsed_args.PATH)
+            print("Waiting on threaded downloads...")
+            dm.end()
+        except Exception as exc:
+            if parsed_args.debug:
+                raise exc from None
+            else:
+                print("Download aborted: %s" % str(exc))
+        except KeyboardInterrupt:
+            print("User canceled download by keyboard interrupt")
 
 
 def main(args):
     # Called via `cometx download ...`
     parser = argparse.ArgumentParser(
         description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter
     )
```

## cometx/cli/reproduce.py

```diff
@@ -92,14 +92,16 @@
     shell_commands = ""
     # "cd %s\n" % os.path.abspath(parsed_args.OUTPUT_DIR)
     if os.path.exists(os.path.join(parsed_args.OUTPUT_DIR, "conda-spec.txt")):
         shell_commands += "conda create --name reproduced-env --file conda-spec.txt\n"
         shell_commands += "conda activate reproduced-env\n"
     if os.path.exists(os.path.join(parsed_args.OUTPUT_DIR, "requirements.txt")):
         shell_commands += "pip install -r requirements.txt\n"
+    if os.path.exists(os.path.join(parsed_args.OUTPUT_DIR, "git_diff.patch")):
+        shell_commands += "git apply git_diff.patch\n"
     if os.path.exists(os.path.join(parsed_args.OUTPUT_DIR, "git_metadata.json")):
         shell_commands += manager.get_git_text(experiment)
         script = "../script.py"
     else:
         script = "script.py"
 
     shell_commands += "%s %s\n" % (parsed_args.executable, script)
```

## cometx/framework/wandb.py

```diff
@@ -12,17 +12,20 @@
 
 import json
 import math
 import os
 import re
 import shutil
 import tempfile
+from concurrent.futures import ThreadPoolExecutor
 from urllib.parse import unquote
 
+import comet_ml
 from comet_ml.cli_args_parse import _parse_cmd_args, _parse_cmd_args_naive
+from comet_ml.data_structure import Histogram
 from comet_ml.utils import makedirs
 
 import wandb
 
 from ..utils import download_url, remove_extra_slashes
 
 MAX_METRIC_SAMPLES = 15_000
@@ -39,28 +42,50 @@
         force=False,
         filename=None,
         asset_type=None,
         overwrite=False,
         skip=False,
         debug=False,
         query=None,
+        max_workers=1,
     ):
         self.api = wandb.Api(timeout=60)
 
         self.root = output if output is not None else os.getcwd()
         self.debug = debug
         self.flat = flat
         self.skip = skip
         self.force = force
         self.filename = filename
         self.asset_type = asset_type
         self.overwrite = overwrite
+        if max_workers > 1:
+            self.queue = ThreadPoolExecutor(max_workers=max_workers)
+        else:
+            self.queue = None
         self.ignore = ignore if ignore else []
         self.include_experiments = None
 
+    def download_file_task(self, path, file):
+        def task():
+            with tempfile.TemporaryDirectory() as tmpdir:
+                file.download(root=tmpdir)
+                shutil.copy(os.path.join(tmpdir, file.name), path)
+
+        if self.queue is None:
+            # Do it now:
+            task()
+        else:
+            # add to queue
+            self.queue.submit(task)
+
+    def end(self):
+        if self.queue is not None:
+            self.queue.shutdown(wait=True)
+
     def reset_run(self):
         self.asset_metadata = []
         self.parameters = []
 
     def download(self, PATH):
         path = remove_extra_slashes(PATH)
         path_parts = path.split("/")
@@ -96,18 +121,28 @@
             path = os.path.join(path, filename)
             # Add to asset metadata:
             if (
                 len(subdirs) > 1
                 and subdirs[0] == "assets"
                 and subdirs[1] != "assets_metadata.jsonl"
             ):
+                step = None
+                log_as_filename = None
+                parts = filename.rsplit("_", 3)
+                _, ext = os.path.splitext(filename)
+                if len(parts) == 3:
+                    log_as_filename, step, _ = parts
+                    log_as_filename += ext
+                    step = int(step)
                 self.asset_metadata.append(
                     {
                         "fileName": filename,
-                        "type": subdirs[1],
+                        "logAsFileName": log_as_filename,
+                        "type": subdirs[1],  # we'll figure out later
+                        "step": step,
                     }
                 )
         return path
 
     def get_file_path(self, wandb_file):
         return "/".join(wandb_file.name.split("/")[:-1])
 
@@ -142,52 +177,94 @@
     def download_data(self, path, data):
         with open(path, "w") as fp:
             fp.write(data + "\n")
 
     def download_model_graph(self, run, file):
         print("    downloading model graph...")
         path = self.get_path(run, "run", filename="graph_definition.txt")
-        self.download_file(path, file)
+        self.download_file_task(path, file)
+
+    def download_metadata(self, run, info, workspace, project):
+        print("    downloading metadata...")
+        metadata = {
+            "experimentName": run.name,
+            "userName": info["username"],
+            "projectName": project,
+            "workspaceName": workspace,
+            "filePath": info["program"],
+            "fileName": info["program"],
+            "cometDownloadVersion": comet_ml.__version__,
+        }
+        path = self.get_path(run, "run", filename="metadata.json")
+        with open(path, "w") as fp:
+            fp.write(json.dumps(metadata) + "\n")
 
     def download_model(self, run, file):
         print("    downloading model...")
         filename = self.get_file_name(file)
         path = self.get_path(run, "assets", "model-element", filename=filename)
-        self.download_file(path, file)
+        self.download_file_task(path, file)
 
     def download_image(self, run, file):
         print("    downloading image...")
         filename = self.get_file_name(file)
         path = self.get_path(run, "assets", "image", filename=filename)
-        self.download_file(path, file)
+        self.download_file_task(path, file)
+
+    def download_audio(self, run, file):
+        print("    downloading audio...")
+        filename = self.get_file_name(file)
+        path = self.get_path(run, "assets", "audio", filename=filename)
+        self.download_file_task(path, file)
+
+    def download_video(self, run, file):
+        print("    downloading video...")
+        filename = self.get_file_name(file)
+        path = self.get_path(run, "assets", "video", filename=filename)
+        self.download_file_task(path, file)
+
+    def download_text(self, run, file):
+        print("    downloading text...")
+        filename = self.get_file_name(file)
+        path = self.get_path(run, "assets", "text", filename=filename)
+        self.download_file_task(path, file)
+
+    def download_html(self, run, file):
+        print("    downloading html...")
+        filename = self.get_file_name(file)
+        path = self.get_path(run, "assets", "html", filename=filename)
+        self.download_file_task(path, file)
 
     def download_asset(self, run, file):
         print("    downloading asset...")
         filename = self.get_file_name(file)
         path = self.get_path(run, "assets", "asset", filename=filename)
-        self.download_file(path, file)
+        self.download_file_task(path, file)
 
     def download_asset_data(self, run, data, filename):
         path = self.get_path(run, "assets", "asset", filename=filename)
         self.download_data(path, data)
 
     def download_code(self, run, file):
         print("    downloading code...")
-        path = self.get_path(run, "run", filename="script.py")
-        self.download_file(path, file)
+        filepath = self.get_file_path(file)
+        filename = self.get_file_name(file)
+        # NOTE: filepath contains "code/"
+        path = self.get_path(run, "run", filepath, filename=filename)
+        self.download_file_task(path, file)
 
     def download_output(self, run, file):
         print("    downloading output...")
         path = self.get_path(run, "run", filename="output.txt")
-        self.download_file(path, file)
+        self.download_file_task(path, file)
 
     def download_dependencies(self, run, file):
         print("    downloading dependencies...")
         path = self.get_path(run, "run", filename="requirements.txt")
-        self.download_file(path, file)
+        self.download_file_task(path, file)
 
     def download_asset_metadata(self, run):
         path = self.get_path(run, "assets", filename="assets_metadata.jsonl")
         with open(path, "w") as fp:
             for metadata in self.asset_metadata:
                 fp.write(json.dumps(metadata) + "\n")
 
@@ -246,89 +323,122 @@
 
             # Handle assets (things that have a filename) here:
             for file in list(run.files()):
                 path = self.get_file_path(file)
                 name = file.name
                 if name.startswith("artifact/"):
                     self.download_artifact(run, file)
-
                 elif path == "media/graph" and "graph" not in self.ignore:
                     self.download_model_graph(run, file)
-                elif path == "code" and "code" not in self.ignore:
+                elif path == "media/images" and "image" not in self.ignore:
+                    # FIXME: bounding boxes, (bb and bit masks are saved in assets)
+                    self.download_image(run, file)
+                elif path == "media/audios" and "audio" not in self.ignore:
+                    self.download_audio(run, file)
+                elif path == "media/videos" and "video" not in self.ignore:
+                    self.download_video(run, file)
+                elif path == "media/text" and "text" not in self.ignore:
+                    self.download_text(run, file)
+                elif path == "media/html" and "html" not in self.ignore:
+                    self.download_html(run, file)
+                elif path.startswith("code") and "code" not in self.ignore:
                     self.download_code(run, file)
                 elif name == "output.log" and "output" not in self.ignore:
                     self.download_output(run, file)
                 elif name == "requirements.txt":
                     self.download_dependencies(run, file)
                 elif name == "wandb-summary.json":
                     with tempfile.TemporaryDirectory() as tmpdirname:
                         summary = json.load(file.download(root=tmpdirname))
-                        # list of all of the metrics
+                        for item in summary:
+                            # FIXME: anything can be logged to a summary.
+                            # Some are not saved as assets, like histograms:
+                            if (
+                                isinstance(summary[item], dict)
+                                and "_type" in summary[item]
+                                and summary[item]["_type"] == "histogram"
+                            ):
+                                self.write_histogram(run, item, summary[item])
                         self.download_asset_data(
                             run, json.dumps(summary), "wandb_summary.json"
                         )
                 elif name == "wandb-metadata.json":
                     ## System info etc
-                    self.download_system_details(run, file)
-                elif name == "diff.patch":
+                    self.download_system_details(run, file, workspace, project)
+                elif name == "diff.patch" and "git" not in self.ignore:
                     self.download_git_patch(run, file)
-                elif "media/images" in path:
-                    self.download_image(run, file)
-                elif any(
-                    extension in name
-                    for extension in [
-                        ".pb",
-                        ".onnx",
-                        ".pkl",
-                        ".mlmodel",
-                        ".pmml",
-                        ".pt",
-                        ".h5",
-                    ]
+                elif (
+                    any(
+                        extension in name
+                        for extension in [
+                            ".pb",
+                            ".onnx",
+                            ".pkl",
+                            ".mlmodel",
+                            ".pmml",
+                            ".pt",
+                            ".h5",
+                        ]
+                    )
+                    and "model" not in self.ignore
                 ):
                     self.download_model(run, file)
-                else:
+                elif "asset" not in self.ignore:
                     self.download_asset(run, file)
 
             # After all of the file downloads, log others:
             self.download_others(run, others)
             self.download_asset_metadata(run)
             self.download_hyper_parameters(run.config)
             self.write_parameters(run)
 
     def download_git_patch(self, run, file):
         path = self.get_path(run, "run", filename="git_diff.patch")
-        self.download_file(path, file)
+        self.download_file_task(path, file)
 
     def download_hyper_parameters(self, config):
         # FIXME: may need to unpack these
         for key, value in config.items():
             self.parameters.append(
                 {
                     "name": key,
                     "valueMax": value,
                     "valueMin": value,
                     "valueCurrent": value,
                     "editable": False,
                 }
             )
 
+    def write_histogram(self, run, name, data):
+        histogram = Histogram()
+        values = [[b] * v for v, b in zip(data["values"], data["bins"])]
+        histogram.add(values)
+        data_dict = {"histograms": [{"step": 0, "histogram": histogram.to_json()}]}
+        # FIXME: clean name for filename
+        path = self.get_path(
+            run, "assets", "histogram_combined_3d", filename="%s.json" % name
+        )
+        with open(path, "w") as fp:
+            fp.write(json.dumps(data_dict) + "\n")
+
     def write_parameters(self, run):
         path = self.get_path(run, filename="parameters.json")
         with open(path, "w") as fp:
             fp.write(json.dumps(self.parameters) + "\n")
 
-    def download_system_details(self, run, file):
+    def download_system_details(self, run, file, workspace, project):
         with tempfile.TemporaryDirectory() as tmpdirname:
             system_and_os_info = json.load(file.download(root=tmpdirname))
         args = system_and_os_info["args"]
         system_details = {
-            "command": [system_and_os_info["program"]] + args
-            if args
-            else [system_and_os_info["program"]],
+            "command": (
+                [system_and_os_info["program"]] + args
+                if args
+                else [system_and_os_info["program"]]
+            ),
             "env": None,
             "hostname": system_and_os_info["host"],
             "ip": "",
             "machine": "",
             "osRelease": system_and_os_info["os"],
             "osType": system_and_os_info["os"],
             "os": system_and_os_info["os"],
@@ -340,14 +450,15 @@
             "user": system_and_os_info["username"],
         }
         path = self.get_path(run, filename="system_details.json")
         with open(path, "w") as fp:
             fp.write(json.dumps(system_details) + "\n")
         # ---
         self.download_cmd_parameters(run, args)
+        self.download_metadata(run, system_and_os_info, workspace, project)
         # ---
         if "git" in system_and_os_info:
             commit = system_and_os_info["git"]["commit"]
             origin = system_and_os_info["git"]["remote"]
             git_metadata = {
                 "parent": commit,
                 "user": None,
@@ -355,26 +466,27 @@
                 "branch": None,
                 "origin": origin,
             }
             path = self.get_path(run, "run", filename="git_metadata.json")
             with open(path, "w") as fp:
                 fp.write(json.dumps(git_metadata) + "\n")
         """
+        # FIXME:
         # Set the filename separately
         ## self.experiment.set_filename(system_and_os_info['program'])
         """
         # Log the entire file as well:
         path = self.get_path(run, "assets", filename="wandb-metadata.json")
         with open(path, "w") as fp:
             fp.write(json.dumps(system_and_os_info) + "\n")
 
     def download_artifact(self, run, file):
         _, artifact_id, artifact_name = file.name.split("/", 2)
         path = self.get_path(run, "artifacts", artifact_id, filename=artifact_name)
-        self.download_file(path, file)
+        self.download_file_task(path, file)
 
     def download_artifact_by_name(
         self,
         workspace,
         project,
         artifact_name,
         alias,
@@ -413,52 +525,67 @@
         for ignore in self.ignore:
             if ignore.startswith("metrics:"):
                 _, regex = ignore.split(":", 1)
                 if re.match(regex, metric):
                     return True
         return False
 
-    def download_metrics(self, run):
-        print("    downloading metrics...")
-        filename = self.get_path(run, filename="metrics.jsonl")
-        with open(filename, "w") as fp:
-            metrics = list(run.history(pandas=False, samples=1)[0].keys())
-            for metric in metrics:
-                if self.ignore_metric_name(metric):
-                    continue
-                metric_data = run.history(
-                    keys=[metric, "_timestamp"],
-                    pandas=False,
-                    samples=MAX_METRIC_SAMPLES,
-                )
+    def download_metric_task(self, metric, run, count):
+        def task():
+            print("        downloading metric %r..." % metric)
+            metric_data = run.history(
+                keys=[metric, "_timestamp"],
+                pandas=False,
+                samples=MAX_METRIC_SAMPLES,
+            )
+            filename = self.get_path(
+                run, "metrics", filename="metric_%05d.jsonl" % count
+            )
+            with open(filename, "w") as fp:
                 for row in metric_data:
                     step = row.get("_step", None)
                     timestamp = row.get("_timestamp", None)
                     value = row.get(metric, None)
-                    if isinstance(value, dict):
-                        # ignore here; artifacts or summary metrics?
-                        pass
-                    else:
-                        if (
-                            metric is not None
-                            and value is not None
-                            and not math.isnan(value)
-                        ):
-                            ts = (
-                                int(timestamp * 1000) if timestamp is not None else None
-                            )
-                            data = {
-                                "metricName": metric,
-                                "metricValue": value,
-                                "timestamp": ts,
-                                "step": step,
-                                "epoch": None,
-                                "runContext": None,
-                            }
-                            fp.write(json.dumps(data) + "\n")
+                    if (
+                        metric is not None
+                        and value is not None
+                        and not math.isnan(value)
+                    ):
+                        ts = int(timestamp * 1000) if timestamp is not None else None
+                        data = {
+                            "metricName": metric,
+                            "metricValue": value,
+                            "timestamp": ts,
+                            "step": step,
+                            "epoch": None,
+                            "runContext": None,
+                        }
+                        fp.write(json.dumps(data) + "\n")
+
+        if self.queue is None:
+            # Do it now:
+            task()
+        else:
+            # add to queue
+            self.queue.submit(task)
+
+    def download_metrics(self, run):
+        print("    downloading metrics...")
+        samples = run.history(pandas=False, samples=1)[0]
+        metrics = list(samples.keys())
+        metrics_summary_path = self.get_path(run, filename="metrics_summary.jsonl")
+        with open(metrics_summary_path, "w") as fp:
+            for count, metric in enumerate(metrics):
+                if self.ignore_metric_name(metric):
+                    continue
+                # Is it a metric?
+                if samples[metric] is None or isinstance(samples[metric], dict):
+                    continue
+                fp.write(json.dumps({"metric": metric, "count": count}) + "\n")
+                self.download_metric_task(metric, run, count)
 
     def download_reports(self, workspace, project):
         if self.flat:
             path = self.root
         else:
             path = os.path.join(self.root, workspace, project, "reports")
```

## cometx/framework/comet/download_manager.py

```diff
@@ -778,15 +778,15 @@
 
         Args:
             experiment: (APIExperiment) the experiment
         """
         if self.flat:
             path = self.root
         else:
-            path = self.get_experiment_path(experiment)
+            path = self.get_experiment_path(experiment, "assets", "html")
 
         filepath = os.path.join(path, "experiment.html")
         if self._should_write(filepath):
             html = experiment.get_html()
             if html:
                 self.summary["html"] += 1
                 makedirs(path, exist_ok=True)
@@ -1049,14 +1049,15 @@
             experiment: (APIExperiment) the experiment
         """
         if self.flat:
             path = self.root
         else:
             path = self.get_experiment_path(experiment, "run")
 
+        # FIXME: now in run/code/*.py, as original filename
         filepath = os.path.join(path, "script.py")
         if self._should_write(filepath):
             code = experiment.get_code()
             if code:
                 self.summary["code"] += 1
                 makedirs(path, exist_ok=True)
                 with open(filepath, "w") as f:
```

## Comparing `cometx-1.4.3.dist-info/LICENSE` & `cometx-2.0.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `cometx-1.4.3.dist-info/METADATA` & `cometx-2.0.0.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: cometx
-Version: 1.4.3
+Version: 2.0.0
 Summary: Python tools for Comet
 Home-page: https://github.com/comet-ml/comet-sdk-extensions/
 Author: cometx development team
 License: MIT License
 Keywords: ai,artificial intelligence,python,machine learning
 Platform: Linux
 Platform: Mac OS X
```

## Comparing `cometx-1.4.3.dist-info/RECORD` & `cometx-2.0.0.dist-info/RECORD`

 * *Files 15% similar despite different names*

```diff
@@ -1,28 +1,28 @@
 cometx/__init__.py,sha256=BrAXZ_G0gGubKyJ1bC41s1Bs9zKGIbsCtGFNXwosiO0,546
 cometx/_typing.py,sha256=I0YU2x7xLMclwkoobUbJHe6k2XuIufQUzawnv-GsEDo,1227
-cometx/_version.py,sha256=8tnTGr8Ze5DeCk_L-G_BK0SaG6hb4iBPUspr0nZOfpc,642
+cometx/_version.py,sha256=Th2IUe-wWbQzt-2KzYg216BDD_X9fGA7Q6oSxQIYrY8,642
 cometx/api.py,sha256=mjW5l-lh2gF68uM--oI6xHYXLxiOmFqgRz0nRnSiEM8,5468
 cometx/generate_utils.py,sha256=kv2SE0YZWOr3l85DJyQOmQh_YprZ_2jDBRDYPb6gLIQ,32107
 cometx/utils.py,sha256=lt9iuHu0oGr6F6_nm4351dxUMxLqpjgJIgz75Z-xQ5Y,5065
 cometx/cli/__init__.py,sha256=voafk9dNZOp6aR4P8rQubaS_pWtvJePWg_gAyO-ayuk,3068
 cometx/cli/config.py,sha256=9XDHgDr2Dz3p54rlHN6cPiPF6vOhaJJzSkDLBEMC7M4,4908
-cometx/cli/copy.py,sha256=PN3fthdnWDQhpHmpkhoXCdsaE8q6MVXNSGi58lp2y9o,23328
+cometx/cli/copy.py,sha256=3kxorrMkwZjlAOsCTCOGfQvI4l29t7pU3CYPQDFXCno,26091
 cometx/cli/delete_assets.py,sha256=0Yn5GZYRhwAxKPVatUyzg7B5RgQRiQwi5GUn0R6lFRE,3891
-cometx/cli/download.py,sha256=I8cYAX8xcbQ7YsnTQ9Lk6at8YOzPESyES9S9kg9joJA,8053
+cometx/cli/download.py,sha256=1C_pR7y7ydUhi8cfbqYwXp-E13ThWfLibdDXLV_WCdM,8496
 cometx/cli/list_command.py,sha256=gstyM4nJ8LJWOdLnm_O6jK7Jctj5w3QUs0pGZVI5DU4,2255
 cometx/cli/log.py,sha256=Q8K6FFSf57zzxdpbh4GUswFkgloj9DU6NCZijgtk-0Y,9772
-cometx/cli/reproduce.py,sha256=Zi5ehfN7ZIjkZC8RdRkixNRuTssdW2znRtN6OXA45-o,4289
+cometx/cli/reproduce.py,sha256=P0D73cKi-BNB7nGFnjgDpseN2UVOqikOLB3uxqH77WI,4423
 cometx/cli/utils.py,sha256=-Cqf4yqQJ72dEATiXdq37URm_aePn-oNwrJvW_AFIgg,6777
 cometx/framework/__init__.py,sha256=EObGelztamarpe5VUuroE-z3ARPNQEeCV1GYo4KiTZg,388
-cometx/framework/wandb.py,sha256=9GPbX4CTkmW7Rr_94BNhlKJP5x-7YJE9MGT2xjxIs3Y,17359
+cometx/framework/wandb.py,sha256=y4SMkLqTaWU8A11G7LzR5ipSYkfqmqOAFp0XVbi4Q0Y,22809
 cometx/framework/comet/__init__.py,sha256=hgl6TWV2cmvaDkfb_jZKnegOso--TCqpPRYriWahfbE,443
-cometx/framework/comet/download_manager.py,sha256=kh88I50x8LTWw6O_ln_BCgRvomTXWX_O-p14LBWMSSg,45984
+cometx/framework/comet/download_manager.py,sha256=qD5Obv4cqcUzSOl0o1JpZuK2un0uJNTu-SBJYgLDfAM,46062
 cometx/tools/__init__.py,sha256=FRj-VhQ5qGHPIwMY9dZZTcBu0HiwsfdvODeZ87Vyio4,379
 cometx/tools/dataset.py,sha256=J_QS0EhDx9Q6wE39Wus4I-pXzwtHDyPbpCJAGms9nCo,2473
 cometx/tools/pointcloud.py,sha256=aO8tqmnAcdzCzFbJ8Lse6wigwAoT_dowMyzLuHGJVqk,10560
-cometx-1.4.3.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-cometx-1.4.3.dist-info/METADATA,sha256=UxTp4naRv7XJoTCIVVBhOUfmeNhjTW-fo2jFEP7Lc4g,11385
-cometx-1.4.3.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-cometx-1.4.3.dist-info/entry_points.txt,sha256=uC7qLDZi6lmkkyl6TNRhcL5O28A_B4aklYU-LgPUPYc,43
-cometx-1.4.3.dist-info/top_level.txt,sha256=zLvh8_4zj6N060ZSiJEPtCZhFamoROgHV8BHmg0QFqA,7
-cometx-1.4.3.dist-info/RECORD,,
+cometx-2.0.0.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+cometx-2.0.0.dist-info/METADATA,sha256=jB8UHj9LQJlCtAvZ2BcueYGzW_Ah9N_cS6ADeek4PRA,11385
+cometx-2.0.0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+cometx-2.0.0.dist-info/entry_points.txt,sha256=uC7qLDZi6lmkkyl6TNRhcL5O28A_B4aklYU-LgPUPYc,43
+cometx-2.0.0.dist-info/top_level.txt,sha256=zLvh8_4zj6N060ZSiJEPtCZhFamoROgHV8BHmg0QFqA,7
+cometx-2.0.0.dist-info/RECORD,,
```

